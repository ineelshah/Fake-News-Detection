{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word2vecimplementation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"15TgsPyAwmM7nHTsXQdQvWLBD2s7fV_0c","authorship_tag":"ABX9TyMD0bwzJmGo9bE4AfR275/g"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"05bMgA7ApRGL","colab_type":"code","outputId":"0ffc4aca-ef31-4c4e-fc20-5b0bcea2efe9","executionInfo":{"status":"ok","timestamp":1585850287428,"user_tz":-330,"elapsed":901,"user":{"displayName":"Neel Shah","photoUrl":"https://lh3.googleusercontent.com/-uqDqdbKVmMs/AAAAAAAAAAI/AAAAAAAACP0/Fe19KJJ8Ji4/s64/photo.jpg","userId":"15671838399494525246"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["wordlen = max(df['word_count'])\n","print(wordlen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["24177\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6_1YhBHjfSZ8","colab_type":"code","outputId":"de2218c8-23aa-4a9d-9e94-6d1c291e5731","executionInfo":{"status":"error","timestamp":1585855150820,"user_tz":-330,"elapsed":4851728,"user":{"displayName":"Neel Shah","photoUrl":"https://lh3.googleusercontent.com/-uqDqdbKVmMs/AAAAAAAAAAI/AAAAAAAACP0/Fe19KJJ8Ji4/s64/photo.jpg","userId":"15671838399494525246"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%tensorflow_version 1.14\n","\n","#importing libraries\n","\n","from numpy import array\n","from numpy import asarray\n","from numpy import zeros\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten, BatchNormalization\n","from keras.layers import Embedding, Dropout, Conv1D, MaxPooling1D\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","#Loading the data in a dataframe\n","\n","\n","\n","df = pd.read_csv('drive/My Drive/The_Research/all_data_refined.csv')\n","docs = df['text'] #Change this accordingly\n","\n","\n","#test\n","\n","for i in range(len(docs)):\n","  if docs[i] == \"\": print(i)\n","\n","#load the labels\n","\n","\n","type = df['type'] #Change this accordingly\n","labels = []\n","\n","for types in type:\n","  if types == 'real':\n","    labels.append(1)\n","  elif types == 'fake':\n","    labels.append(0)\n","\n","\n","print(docs)\n","\n","# prepare tokenizer\n","t = Tokenizer()\n","t.fit_on_texts(docs)\n","vocab_size = len(t.word_index) + 1\n","\n","\n","\n","# integer encode the documents\n","encoded_docs = t.texts_to_sequences(docs)\n","print(encoded_docs)\n","\n","\n","# pad documents to a max length\n","\n","\n","\n","\n","wordlen = max(df['word_count'])\n","print(wordlen)\n","\n","\n","\n","\n","\n","max_length = wordlen # Change this if needed\n","print(\"Max_Length: \", max_length)\n","padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n","print(padded_docs)\n","\n","\n","# load the whole embedding into memory\n","embeddings_index = dict()\n","f = open('drive/My Drive/glove_data/glove.6B/glove.6B.100d.txt')\n","for line in f:\n","\tvalues = line.split()\n","\tword = values[0]\n","\tcoefs = asarray(values[1:], dtype='float32')\n","\tembeddings_index[word] = coefs\n","f.close()\n","print('Loaded %s word vectors.' % len(embeddings_index))\n","\n","\n","# create a weight matrix for words in training docs\n","embedding_matrix = zeros((vocab_size, 100))\n","for word, i in t.word_index.items():\n","\tembedding_vector = embeddings_index.get(word)\n","\tif embedding_vector is not None:\n","\t\tembedding_matrix[i] = embedding_vector\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.33)\n","\n","# define model\n","model = Sequential()\n","e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n","model.add(e)\n","model.add(Dropout(0.5))\n","#model.add(e)\n","model.add(Conv1D(filters=10, kernel_size=(4)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.8))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","# summarize the model\n","print(\"____________________\")\n","print(model.summary())\n","print(\"____________________\")\n","\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=5, verbose=1)\n","\n","\n","# evaluate the model\n","print(\"____________________\")\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n","print('Accuracy: %f' % (accuracy*100))\n","\n","\n","print(\"____________________\")\n","output = model.predict(X_test)\n","print(output)\n","\n","# save the model\n","model.save('modelword2vec.h5')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.14`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow is already loaded. Please restart the runtime to change versions.\n","0        They stood in line at Trump Tower, sometimes u...\n","1        Donald J. Trump s foundation informed Attorney...\n","2        President-elect Donald J. Trump won the White ...\n","3        An investment pitch for a new Texas hotel is t...\n","4        President-elect Donald J. Trump s wife, Melani...\n","                               ...                        \n","20010    Most conservatives who oppose marriage equalit...\n","20011    The freshman senator from Georgia quoted scrip...\n","20012    The State Department told the Republican Natio...\n","20013    ADDIS ABABA, Ethiopia President Obama convened...\n","20014    Jeb Bush Is Suddenly Attacking Trump. Here's W...\n","Name: text, Length: 20015, dtype: object\n"],"name":"stdout"},{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[[   30  2130     6 ...     0     0     0]\n"," [   98   753    21 ...     0     0     0]\n"," [   60   520    98 ...     0     0     0]\n"," ...\n"," [    1    69   256 ...     0     0     0]\n"," [24550 29989  6260 ...     0     0     0]\n"," [ 1897   331     8 ...     0     0     0]]\n","Loaded 400000 word vectors.\n","____________________\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_10 (Embedding)     (None, 24177, 100)        16347600  \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 24177, 100)        0         \n","_________________________________________________________________\n","conv1d_10 (Conv1D)           (None, 24174, 10)         4010      \n","_________________________________________________________________\n","max_pooling1d_10 (MaxPooling (None, 12087, 10)         0         \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 120870)            0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 128)               15471488  \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 128)               512       \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 1)                 129       \n","=================================================================\n","Total params: 31,823,739\n","Trainable params: 15,475,883\n","Non-trainable params: 16,347,856\n","_________________________________________________________________\n","None\n","____________________\n","Epoch 1/5\n","13410/13410 [==============================] - 933s 70ms/step - loss: 0.5960 - acc: 0.7519\n","Epoch 2/5\n","13410/13410 [==============================] - 929s 69ms/step - loss: 0.4046 - acc: 0.8256\n","Epoch 3/5\n","13410/13410 [==============================] - 932s 70ms/step - loss: 0.3644 - acc: 0.8447\n","Epoch 4/5\n","13410/13410 [==============================] - 933s 70ms/step - loss: 0.3432 - acc: 0.8582\n","Epoch 5/5\n","13410/13410 [==============================] - 932s 70ms/step - loss: 0.3291 - acc: 0.8583\n","____________________\n","6605/6605 [==============================] - 84s 13ms/step\n","Accuracy: 86.510220\n","____________________\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-f0b68b6e4caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"____________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"DNFJot0rff_q","colab_type":"code","outputId":"668e6edd-af95-4b7e-9830-18eb2cf22323","executionInfo":{"status":"ok","timestamp":1585849484631,"user_tz":-330,"elapsed":1000,"user":{"displayName":"Neel Shah","photoUrl":"https://lh3.googleusercontent.com/-uqDqdbKVmMs/AAAAAAAAAAI/AAAAAAAACP0/Fe19KJJ8Ji4/s64/photo.jpg","userId":"15671838399494525246"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df[:5653]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>language</th>\n","      <th>main_img_url</th>\n","      <th>published</th>\n","      <th>text</th>\n","      <th>title</th>\n","      <th>type</th>\n","      <th>uuid</th>\n","      <th>word_count</th>\n","      <th>average_word_count</th>\n","      <th>exclamation_count</th>\n","      <th>capital_count</th>\n","      <th>question_count</th>\n","      <th>negation_count</th>\n","      <th>fpp_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.0</td>\n","      <td>english</td>\n","      <td>https://static01.nyt.com/images/2016/11/23/us/...</td>\n","      <td>2016-11-23 00:45:32</td>\n","      <td>They stood in line at Trump Tower, sometimes u...</td>\n","      <td>At Donald Trumps Properties, a Showcase for a ...</td>\n","      <td>real</td>\n","      <td>f182f05dc3191ba4cb741e22f75fb43b</td>\n","      <td>1082</td>\n","      <td>12.729412</td>\n","      <td>0</td>\n","      <td>230</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.0</td>\n","      <td>english</td>\n","      <td>https://static01.nyt.com/images/2016/10/18/us/...</td>\n","      <td>2016-10-17 18:46:52</td>\n","      <td>Donald J. Trump s foundation informed Attorney...</td>\n","      <td>Trump Foundation Tells New York It Has Stopped...</td>\n","      <td>real</td>\n","      <td>220b87845a5eb01509b66c8008bf3728</td>\n","      <td>344</td>\n","      <td>10.117647</td>\n","      <td>0</td>\n","      <td>67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.0</td>\n","      <td>english</td>\n","      <td>https://static01.nyt.com/images/2016/11/12/us/...</td>\n","      <td>2016-11-12 02:08:39</td>\n","      <td>President-elect Donald J. Trump won the White ...</td>\n","      <td>Donald Trump Prepares for White House Move, bu...</td>\n","      <td>real</td>\n","      <td>247e97e1da2dc67fcb31e20b84b2d960</td>\n","      <td>1090</td>\n","      <td>16.268657</td>\n","      <td>1</td>\n","      <td>189</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6.0</td>\n","      <td>english</td>\n","      <td>https://static01.nyt.com/images/2016/10/21/bus...</td>\n","      <td>2016-10-20 22:09:04</td>\n","      <td>An investment pitch for a new Texas hotel is t...</td>\n","      <td>Luring Chinese Investors With Trumps Name, and...</td>\n","      <td>real</td>\n","      <td>e1f572512a36071cbca6056a31577389</td>\n","      <td>1302</td>\n","      <td>13.151515</td>\n","      <td>0</td>\n","      <td>283</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.0</td>\n","      <td>english</td>\n","      <td>https://static01.nyt.com/images/2016/11/21/us/...</td>\n","      <td>2016-11-21 01:42:23</td>\n","      <td>President-elect Donald J. Trump s wife, Melani...</td>\n","      <td>Melania and Barron Trump Wont Immediately Move...</td>\n","      <td>real</td>\n","      <td>584700e476e0d3c20731cb3d28e6ce2b</td>\n","      <td>518</td>\n","      <td>14.000000</td>\n","      <td>0</td>\n","      <td>115</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5648</th>\n","      <td>NaN</td>\n","      <td>english</td>\n","      <td>http://anonhq.com/wp-content/uploads/2016/10/C...</td>\n","      <td>2016-10-29 00:00:00</td>\n","      <td>On September 5, 2006, Eli Chomsky was an edito...</td>\n","      <td>Hillary: Leaked Audio of Her Discussing Riggin...</td>\n","      <td>fake</td>\n","      <td>e400c4fa1c0dbf380fedc97c5f05ad4395d2dc5f</td>\n","      <td>50</td>\n","      <td>12.500000</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5649</th>\n","      <td>NaN</td>\n","      <td>english</td>\n","      <td>http://anonhq.com/wp-content/uploads/2016/10/b...</td>\n","      <td>2016-10-29 00:00:00</td>\n","      <td>By Amanda Froelich at trueactivist.com\\nDuring...</td>\n","      <td>Thousands Of Buffalo Appear At Site Of Standin...</td>\n","      <td>fake</td>\n","      <td>dd748bfc6ae040829af4b79a0ccfdac2cdc59d44</td>\n","      <td>273</td>\n","      <td>21.000000</td>\n","      <td>0</td>\n","      <td>54</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5650</th>\n","      <td>NaN</td>\n","      <td>english</td>\n","      <td>http://anonhq.com/wp-content/uploads/2016/10/d...</td>\n","      <td>2016-10-29 12:25:00</td>\n","      <td>When I attempt to share your stuff on Facebook...</td>\n","      <td>notitle</td>\n","      <td>fake</td>\n","      <td>65924f23798ba972ab4c0b9384d24e4b650c15c0</td>\n","      <td>26</td>\n","      <td>8.666667</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5651</th>\n","      <td>NaN</td>\n","      <td>english</td>\n","      <td>http://anonhq.com/wp-content/uploads/2016/10/p...</td>\n","      <td>2016-10-29 00:00:00</td>\n","      <td>You want to support Anonymous Independent &amp; In...</td>\n","      <td>A List of Best Password Managers Offering Both...</td>\n","      <td>fake</td>\n","      <td>a13207d9f7fe70c549568c6e37e329e34dbd34db</td>\n","      <td>57</td>\n","      <td>14.250000</td>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5652</th>\n","      <td>NaN</td>\n","      <td>english</td>\n","      <td>http://anonhq.com/wp-content/uploads/2016/10/j...</td>\n","      <td>2016-10-29 11:17:00</td>\n","      <td>NaN</td>\n","      <td>notitle</td>\n","      <td>fake</td>\n","      <td>1ab0c1720010553514360b0a089bd925f7822c76</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5653 rows Ã— 15 columns</p>\n","</div>"],"text/plain":["       id language  ... negation_count fpp_count\n","0     3.0  english  ...              0         3\n","1     4.0  english  ...              0         0\n","2     5.0  english  ...              0         2\n","3     6.0  english  ...              0         3\n","4     7.0  english  ...              0         0\n","...   ...      ...  ...            ...       ...\n","5648  NaN  english  ...              0         0\n","5649  NaN  english  ...              0         0\n","5650  NaN  english  ...              0         0\n","5651  NaN  english  ...              0         1\n","5652  NaN  english  ...              0         0\n","\n","[5653 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"SacEYDVdvw7S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0QBryoARolY3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uAkcXjKEyWZ8","colab_type":"text"},"source":[""]}]}